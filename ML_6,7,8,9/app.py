# N·ªòI DUNG C·ª¶A FILE app.py

import streamlit as st
import joblib
import numpy as np
import re
import string
from nltk.stem import PorterStemmer
from nltk.tokenize import TweetTokenizer
from nltk.corpus import stopwords

# ==========================================================
# B∆Ø·ªöC 1: SAO CH√âP C√ÅC H√ÄM TI·ªÜN √çCH T·ª™ NOTEBOOK V√ÄO ƒê√ÇY
# C√°c h√†m n√†y ph·∫£i gi·ªëng h·ªát l√∫c b·∫°n hu·∫•n luy·ªán m√¥ h√¨nh.
# ==========================================================

# T·∫£i stopwords m·ªôt l·∫ßn duy nh·∫•t
try:
    stopwords_english = stopwords.words('english')
except LookupError:
    import nltk
    nltk.download('stopwords')
    stopwords_english = stopwords.words('english')

def process_tweet(tweet):
    stemmer = PorterStemmer()
    tweet = re.sub(r'^\$?\w*', '', tweet)
    tweet = re.sub(r'^RT[\s]+', '', tweet)
    tweet = re.sub(r'https?:\/\/.*[\r\n]*', '', tweet)
    tweet = re.sub(r'#', '', tweet)
    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)
    tweet_tokens = tokenizer.tokenize(tweet)
    tweets_clean = []
    for word in tweet_tokens:
        if (word not in stopwords_english and word not in string.punctuation):
            stem_word = stemmer.stem(word)
            tweets_clean.append(stem_word)
    return tweets_clean

def extract_six_features(tweet, freqs):
    word_l = process_tweet(tweet)
    first_second_pronouns = {'i', 'me', 'myself', 'we', 'us', 'ourself', 'ourselves', 'you', 'yourself', 'yourselves'}
    x = np.zeros((1, 7))
    x[0,0] = 1 # Bias term
    for word in word_l:
        x[0,1] += freqs.get((word, 1.0), 0)
        x[0,2] += freqs.get((word, 0.0), 0)
        if word in first_second_pronouns:
            x[0,4] += 1
    x[0,3] = 1 if 'no' in word_l else 0
    x[0,5] = 1 if '!' in tweet else 0
    x[0,6] = np.log(len(word_l) + 1)
    return x

# ==========================================================
# B∆Ø·ªöC 2: T·∫¢I MODEL V√Ä T·ª™ ƒêI·ªÇN ƒê√É L∆ØU
# ==========================================================

try:
    model_pipeline = joblib.load('knn_sentiment_pipeline.pkl')
    freqs = joblib.load('freqs.pkl')
except FileNotFoundError:
    st.error("L·ªói: Kh√¥ng t√¨m th·∫•y file model ho·∫∑c freqs. Vui l√≤ng ch·∫°y notebook ƒë·ªÉ t·∫°o c√°c file .pkl tr∆∞·ªõc.")
    st.stop()

# ==========================================================
# B∆Ø·ªöC 3: X√ÇY D·ª∞NG GIAO DI·ªÜN STREAMLIT

# ==========================================================

st.set_page_config(page_title="Ph√¢n t√≠ch C·∫£m x√∫c", page_icon="üí¨", layout="centered")
st.title("üí¨ B·ªô ph√¢n t√≠ch C·∫£m x√∫c Tweet")
st.write("·ª®ng d·ª•ng n√†y s·ª≠ d·ª•ng m√¥ h√¨nh K-Nearest Neighbors (KNN) ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·ªÉ d·ª± ƒëo√°n c·∫£m x√∫c c·ªßa m·ªôt c√¢u tweet l√† T√≠ch c·ª±c hay Ti√™u c·ª±c.")

# √î nh·∫≠p li·ªáu
user_input = st.text_area("Nh·∫≠p c√¢u tweet c·ªßa b·∫°n (b·∫±ng ti·∫øng Anh):", "This movie was absolutely fantastic! I loved every minute of it.")

# N√∫t b·∫•m d·ª± ƒëo√°n
if st.button("Ph√¢n t√≠ch"):
    if user_input:
        # 1. Tr√≠ch xu·∫•t 7 features (bao g·ªìm bias)
        features = extract_six_features(user_input, freqs)
        
        # 2. D·ª± ƒëo√°n b·∫±ng pipeline
        # Pipeline s·∫Ω t·ª± ƒë·ªông scale d·ªØ li·ªáu r·ªìi m·ªõi ƒë∆∞a v√†o m√¥ h√¨nh KNN
        prediction = model_pipeline.predict(features)
        prediction_proba = model_pipeline.predict_proba(features)
        
        # 3. Hi·ªÉn th·ªã k·∫øt qu·∫£
        st.subheader("K·∫øt qu·∫£ ph√¢n t√≠ch:")
        if prediction[0] == 1.0:
            st.success(f"D·ª± ƒëo√°n: T√≠ch c·ª±c (Positive) üòä")
            st.write(f"ƒê·ªô tin c·∫≠y: {prediction_proba[0][1]*100:.2f}%")
        else:
            st.error(f"D·ª± ƒëo√°n: Ti√™u c·ª±c (Negative) üò†")
            st.write(f"ƒê·ªô tin c·∫≠y: {prediction_proba[0][0]*100:.2f}%")
            
    else:
        st.warning("Vui l√≤ng nh·∫≠p m·ªôt c√¢u tweet ƒë·ªÉ ph√¢n t√≠ch.")